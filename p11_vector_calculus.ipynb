{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本节学习vector 对 vector的求导\n",
    "# 也就是多个输入，多个输出的时候，怎么求导\n",
    "# 基本原则与链式法则一致，求导的结果被称为雅可比(Jacobian)矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N个输入，M个输出，求导结果为M*N大小的矩阵\n",
    "# 每个输出对每个输入单独求导\n",
    "\n",
    "# 示例：线性函数 y=Ax+b\n",
    "# J= ∂y / ∂x = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian Matrix:\n",
      "tensor([[2., 3.],\n",
      "        [4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义输入向量 x (n=2 维度)，设置 requires_grad=True\n",
    "x = torch.tensor([0.0, 0.0], requires_grad=True)\n",
    "\n",
    "# 定义矩阵 A (n=2, m=2) 和向量 b (m=2)\n",
    "A = torch.tensor([[2.0, 3.0], [4.0, 5.0]])\n",
    "b = torch.tensor([6.0, 7.0])\n",
    "\n",
    "# 定义函数 func，计算 y = A @ x + b\n",
    "def func(x):\n",
    "    return A @ x + b\n",
    "\n",
    "# 计算 Jacobian 矩阵\n",
    "jacobian = torch.autograd.functional.jacobian(func, x)\n",
    "\n",
    "print(\"Jacobian Matrix:\")\n",
    "print(jacobian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Vector (一阶导数):\n",
      "tensor([  2.,  12., 108.])\n",
      "\n",
      "Hessian Matrix (二阶导数):\n",
      "tensor([[  2.,   0.,   0.],\n",
      "        [  0.,  12.,   0.],\n",
      "        [  0.,   0., 108.]])\n"
     ]
    }
   ],
   "source": [
    "# 特殊情况 多输入 单输出\n",
    "\n",
    "# “多输入单输出”的一阶导数结果，称之为梯度向量\n",
    "# “多输入单输出”的二阶导数结果，称之为Hessian矩阵，梯度向量的每个结果对每个变量求导\n",
    "\n",
    "import torch\n",
    "\n",
    "# 定义多个输入变量，设置 requires_grad=True\n",
    "x1 = torch.tensor(1.0, requires_grad=True)\n",
    "x2 = torch.tensor(2.0, requires_grad=True)\n",
    "x3 = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "# 定义计算输出的函数\n",
    "def func(x1, x2, x3):\n",
    "    return x1**2 + x2**3 + x3**4\n",
    "\n",
    "# 计算输出\n",
    "y = func(x1, x2, x3)\n",
    "\n",
    "# 计算一阶导数（梯度向量）\n",
    "gradient = torch.autograd.grad(y, (x1, x2, x3), create_graph=True)\n",
    "\n",
    "print(\"Gradient Vector (一阶导数):\")\n",
    "print(torch.tensor([g.item() for g in gradient]))\n",
    "\n",
    "# 计算二阶导数（Hessian 矩阵）\n",
    "def compute_hessian(gradient, inputs):\n",
    "    hessian = []\n",
    "    for g in gradient:\n",
    "        hessian_row = torch.autograd.grad(g, inputs, retain_graph=True, allow_unused=True)\n",
    "        hessian_row = [hr if hr is not None else torch.zeros_like(inp) for hr, inp in zip(hessian_row, inputs)]\n",
    "        hessian.append(torch.stack(hessian_row))\n",
    "    return torch.stack(hessian)\n",
    "\n",
    "# 计算 Hessian 矩阵\n",
    "inputs = (x1, x2, x3)\n",
    "hessian = compute_hessian(gradient, inputs)\n",
    "\n",
    "print(\"\\nHessian Matrix (二阶导数):\")\n",
    "print(hessian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "理论验证\n",
    "\n",
    "对于函数 $ y = x_1^2 + x_2^3 + x_3^4 $，其梯度和 Hessian 矩阵为：\n",
    "\n",
    "1. 梯度向量\n",
    "\n",
    "$$\n",
    "\\text{Gradient} = \\left[ 2x_1, 3x_2^2, 4x_3^3 \\right]\n",
    "$$\n",
    "\n",
    "代入 $ x_1 = 1.0 $, $ x_2 = 2.0 $, $ x_3 = 3.0 $，得到：\n",
    "\n",
    "$$\n",
    "\\text{Gradient} = \\left[ 2, 12, 108 \\right]\n",
    "$$\n",
    "\n",
    "2. Hessian 矩阵\n",
    "\n",
    "$$\n",
    "\\text{Hessian} = \\begin{bmatrix}\n",
    "2 & 0 & 0 \\\\\n",
    "0 & 6x_2 & 0 \\\\\n",
    "0 & 0 & 12x_3^2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "代入 $ x_1 = 1.0 $, $ x_2 = 2.0 $, $ x_3 = 3.0 $，得到：\n",
    "\n",
    "$$\n",
    "\\text{Hessian} = \\begin{bmatrix}\n",
    "2 & 0 & 0 \\\\\n",
    "0 & 12 & 0 \\\\\n",
    "0 & 0 & 108\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian Matrix:\n",
      "tensor([[6., 6.],\n",
      "        [8., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# 多输入多输出求导的链式法则\n",
    "# 与普通的链式法则类似 ∂y / ∂x = (∂y / ∂u) * (∂u / ∂x)\n",
    "\n",
    "import torch\n",
    "\n",
    "# 定义输入变量\n",
    "x1 = torch.tensor(1.0, requires_grad=True)\n",
    "x2 = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "# 定义中间变量\n",
    "u1 = x1 + x2\n",
    "u2 = x1 * x2\n",
    "\n",
    "# 定义输出变量\n",
    "y1 = u1**2\n",
    "y2 = u2**2\n",
    "\n",
    "# 计算输出对输入的导数\n",
    "y = torch.stack([y1, y2])  # y 的形状是 [2]\n",
    "\n",
    "# 设置 grad_outputs 为与 y 形状匹配的张量\n",
    "grad_outputs = torch.eye(2)  # 形状是 [2, 2]\n",
    "\n",
    "# 计算 Jacobian 矩阵\n",
    "jacobian = []\n",
    "for i in range(2):\n",
    "    grad = torch.autograd.grad(y[i], [x1, x2], grad_outputs=torch.ones_like(y[i]), retain_graph=True)\n",
    "    jacobian.append(grad)\n",
    "\n",
    "# 将结果堆叠为 Jacobian 矩阵\n",
    "jacobian = torch.stack([torch.stack(row) for row in jacobian])\n",
    "\n",
    "# 打印结果\n",
    "print(\"Jacobian Matrix:\")\n",
    "print(jacobian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx: tensor(16.)\n"
     ]
    }
   ],
   "source": [
    "# 特殊情况：单输入-多输出-单输出\n",
    "# 大小为 1*2 的矩阵，乘以大小为 2*1 的矩阵，得到大小为 1*1 的矩阵\n",
    "import torch\n",
    "\n",
    "# 定义输入变量\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "# 定义中间变量\n",
    "u1 = x**2\n",
    "u2 = x**3\n",
    "\n",
    "# 定义输出变量\n",
    "y = u1 + u2\n",
    "\n",
    "# 计算 y 对 x 的导数\n",
    "y.backward()\n",
    "\n",
    "# 打印结果\n",
    "print(\"dy/dx:\", x.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
